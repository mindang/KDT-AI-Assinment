{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1번. CNN & RNN\n",
    "\n",
    "## 1.1 CNN cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "def seed_everything(seed):\n",
    "    #random.seed(seed)\n",
    "    #os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "seed_everything(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "50000 10000 10000\n"
     ]
    }
   ],
   "source": [
    "# prepare Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "batch_size = 256\n",
    "valid_data_size = 10000\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar10_data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train, validset = torch.utils.data.random_split(trainset, [len(trainset) - valid_data_size, valid_data_size])\n",
    "testset = torchvision.datasets.CIFAR10(root='./cifar10_data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "print(len(trainloader.dataset),len(validloader.dataset),len(testloader.dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainig code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(model_name,model,train_loader,valid_loader,device):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "                                            lr_lambda=lambda epoch: 0.97 ** epoch)\n",
    "    n_epochs = 100\n",
    "\n",
    "    train_loss_list , valid_loss_list = [] , []\n",
    "    best_score = float('inf')\n",
    "\n",
    "    model.train()\n",
    "    patience = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = 0.0\n",
    "        for data, target in train_loader:\n",
    "            data , target = data.to(device) , target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "        scheduler.step()\n",
    "        train_loss_list.append(train_loss/len(train_loader.dataset))\n",
    "\n",
    "        # valid_data\n",
    "        with torch.no_grad():\n",
    "            valid_loss = 0.0\n",
    "            for data, target in valid_loader:\n",
    "                data , target = data.to(device) , target.to(device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                valid_loss += loss.item()*data.size(0)\n",
    "            valid_loss_list.append(valid_loss/len(valid_loader.dataset))\n",
    "        \n",
    "            print('Epoch: {} \\tTraining Loss: {:.6f} \\t valid Loss: {:.6f}'.format(epoch+1, train_loss_list[-1],valid_loss_list[-1]))\n",
    "            \n",
    "        if valid_loss_list[-1] < best_score:\n",
    "            best_score = valid_loss_list[-1]\n",
    "            torch.save(model.state_dict(), os.path.join('./model_data/', '{}_{}.pth'.format(model_name,'best')))\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience == 8:\n",
    "                return train_loss_list , valid_loss_list\n",
    "\n",
    "def test_model(model_name,model,test_loader,device):\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join('./model_data/', '{}_{}.pth'.format(model_name,'best'))))\n",
    "\n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()*data.size(0)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "        for i in range(len(target.data)):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "        \n",
    "            \n",
    "    test_loss = test_loss/len(test_loader.dataset)\n",
    "    print(f'{model_name}=========================================================')\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    for i in range(10):\n",
    "        if class_total[i] > 0:\n",
    "            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "                str(i), 100 * class_correct[i] / class_total[i],\n",
    "                np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "        else:\n",
    "            print('Test Accuracy of %5s: N/A (no training examples)' % (str(i)))\n",
    "\n",
    "    print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "        100. * np.sum(class_correct) / np.sum(class_total),\n",
    "        np.sum(class_correct), np.sum(class_total)))\n",
    "    print('==========================================================================')\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet/VGG/ResNet/DenseNet 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    [common preprocessing]\n",
    "        resie 256*256 -> central_crop 224*224  \n",
    "        mean=[0.485, 0.456, 0.406] std=[0.229, 0.224, 0.225]\n",
    "\n",
    "    [AlexNet config]\n",
    "        num_params : 61,100,840\n",
    "\n",
    "    [VGG19]\n",
    "        BN은 사용x 후에 Batch Normalization에서 적용\n",
    "        num_params : 143,667,240\n",
    "\n",
    "    [ResNet50]\n",
    "        50 vs 101 vs 152가 성능이 비슷비슷해서 효율이 좋은 ResNet50 사용\n",
    "        num_params : 25,557,032\n",
    "    \n",
    "    [DenseNet161]\n",
    "        121부터 201까지 있는데 가장 성능이 좋은 161사용 \n",
    "        특이하게도 layer수가 많아질수록 imageNet 성능이 안좋음\n",
    "        num_params : 28,681,000\n",
    "'''\n",
    "\n",
    "from torchvision.models import alexnet, AlexNet_Weights \n",
    "from torchvision.models import vgg19, VGG19_Weights\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.models import densenet161, DenseNet161_Weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model finetuing\n",
    "\n",
    "기존의 pretrained 모델은 224*224 image입력을 받음\n",
    "\n",
    "cifar10은 32*32 image임\n",
    "\n",
    "따라서 max pooling 모두 제거 , adaptivepooling으로 최종 feature size맞추기\n",
    "\n",
    "ResNet과 DenseNet은 첫번째 pooling만 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet161_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet161_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer25): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer26): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer27): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer28): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer29): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer30): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer31): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer32): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer33): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer34): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer35): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer36): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=2208, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = densenet161(weights=DenseNet161_Weights)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_finetuned_model(model_name,update_conv=False):\n",
    "    if model_name == 'alex' : \n",
    "        class New_alexnet(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(New_alexnet, self).__init__()\n",
    "            \n",
    "                self.features = alexnet(weights=AlexNet_Weights).features\n",
    "                new_features = [layer for layer in self.features if not isinstance(layer, torch.nn.MaxPool2d)]\n",
    "                self.features = torch.nn.Sequential(*new_features)\n",
    "\n",
    "                self.avgpool = alexnet(weights=AlexNet_Weights).avgpool\n",
    "\n",
    "\n",
    "                self.classifier = alexnet(weights=AlexNet_Weights).classifier\n",
    "                self.classifier[6] = nn.Linear(4096, 10)\n",
    "\n",
    "                if not update_conv:\n",
    "                    for param in self.features.parameters():\n",
    "                        param.requires_grad = False\n",
    "\n",
    "            def forward(self, x):\n",
    "                x = self.features(x)\n",
    "                x = self.avgpool(x)\n",
    "                x = torch.flatten(x, 1)\n",
    "                x = self.classifier(x)\n",
    "                return x\n",
    "        model = New_alexnet()\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    elif model_name == 'vgg' : \n",
    "        class New_vgg19(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(New_vgg19, self).__init__()\n",
    "            \n",
    "                self.features = vgg19(weights=VGG19_Weights).features\n",
    "                new_features = [layer for layer in self.features if not isinstance(layer, torch.nn.MaxPool2d)]\n",
    "                self.features = torch.nn.Sequential(*new_features)\n",
    "\n",
    "                self.avgpool = vgg19(weights=VGG19_Weights).avgpool\n",
    "\n",
    "                self.classifier = vgg19(weights=VGG19_Weights).classifier\n",
    "                self.classifier[6] = nn.Linear(4096, 10)\n",
    "\n",
    "                if not update_conv:\n",
    "                    for param in self.features.parameters():\n",
    "                        param.requires_grad = False\n",
    "\n",
    "            def forward(self, x):\n",
    "                x = self.features(x)\n",
    "                x = self.avgpool(x)\n",
    "                x = torch.flatten(x, 1)\n",
    "                x = self.classifier(x)\n",
    "                return x\n",
    "        model = New_vgg19()\n",
    "        return model\n",
    "        \n",
    "\n",
    "    elif model_name == 'resnet':\n",
    "        model = resnet50(weights=ResNet50_Weights)\n",
    "        if not update_conv:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "        model.maxpool = nn.Identity()\n",
    "        model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "        return model\n",
    "    \n",
    "    elif model_name == 'densenet':\n",
    "        model = densenet161(weights=DenseNet161_Weights)\n",
    "        if not update_conv:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "        model.features.pool0 = nn.Identity()\n",
    "        #del model.features.transition1[3]\n",
    "        #del model.features.transition2[3]\n",
    "        #del model.features.transition3[3]\n",
    "    \n",
    "        model.classifier = nn.Linear(model.classifier.in_features, 10)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alex training start\n",
      "Epoch: 1 \tTraining Loss: 1.145617 \t valid Loss: 0.959292\n",
      "Epoch: 2 \tTraining Loss: 0.917835 \t valid Loss: 0.914449\n",
      "Epoch: 3 \tTraining Loss: 0.827853 \t valid Loss: 0.799198\n",
      "Epoch: 4 \tTraining Loss: 0.762573 \t valid Loss: 0.694948\n",
      "Epoch: 5 \tTraining Loss: 0.707732 \t valid Loss: 0.712366\n",
      "Epoch: 6 \tTraining Loss: 0.662267 \t valid Loss: 0.631578\n",
      "Epoch: 7 \tTraining Loss: 0.612045 \t valid Loss: 0.605816\n",
      "Epoch: 8 \tTraining Loss: 0.571567 \t valid Loss: 0.549021\n",
      "Epoch: 9 \tTraining Loss: 0.533611 \t valid Loss: 0.505672\n",
      "Epoch: 10 \tTraining Loss: 0.504400 \t valid Loss: 0.491592\n",
      "Epoch: 11 \tTraining Loss: 0.464479 \t valid Loss: 0.443604\n",
      "Epoch: 12 \tTraining Loss: 0.435982 \t valid Loss: 0.432084\n",
      "Epoch: 13 \tTraining Loss: 0.411360 \t valid Loss: 0.391992\n",
      "Epoch: 14 \tTraining Loss: 0.382229 \t valid Loss: 0.357718\n",
      "Epoch: 15 \tTraining Loss: 0.360526 \t valid Loss: 0.362410\n",
      "Epoch: 16 \tTraining Loss: 0.338175 \t valid Loss: 0.345248\n",
      "Epoch: 17 \tTraining Loss: 0.313486 \t valid Loss: 0.298507\n",
      "Epoch: 18 \tTraining Loss: 0.295562 \t valid Loss: 0.273254\n",
      "Epoch: 19 \tTraining Loss: 0.274531 \t valid Loss: 0.260781\n",
      "Epoch: 20 \tTraining Loss: 0.259848 \t valid Loss: 0.263710\n",
      "Epoch: 21 \tTraining Loss: 0.246452 \t valid Loss: 0.228562\n",
      "Epoch: 22 \tTraining Loss: 0.231286 \t valid Loss: 0.219226\n",
      "Epoch: 23 \tTraining Loss: 0.225400 \t valid Loss: 0.228445\n",
      "Epoch: 24 \tTraining Loss: 0.209029 \t valid Loss: 0.197554\n",
      "Epoch: 25 \tTraining Loss: 0.197677 \t valid Loss: 0.189521\n",
      "Epoch: 26 \tTraining Loss: 0.187424 \t valid Loss: 0.178215\n",
      "Epoch: 27 \tTraining Loss: 0.179037 \t valid Loss: 0.176088\n",
      "Epoch: 28 \tTraining Loss: 0.169794 \t valid Loss: 0.161858\n",
      "Epoch: 29 \tTraining Loss: 0.163576 \t valid Loss: 0.155575\n",
      "Epoch: 30 \tTraining Loss: 0.153202 \t valid Loss: 0.151752\n",
      "Epoch: 31 \tTraining Loss: 0.151727 \t valid Loss: 0.146276\n",
      "Epoch: 32 \tTraining Loss: 0.144517 \t valid Loss: 0.135443\n",
      "Epoch: 33 \tTraining Loss: 0.135566 \t valid Loss: 0.130933\n",
      "Epoch: 34 \tTraining Loss: 0.133812 \t valid Loss: 0.125049\n",
      "Epoch: 35 \tTraining Loss: 0.127859 \t valid Loss: 0.125412\n",
      "Epoch: 36 \tTraining Loss: 0.125573 \t valid Loss: 0.121574\n",
      "Epoch: 37 \tTraining Loss: 0.119674 \t valid Loss: 0.118441\n",
      "Epoch: 38 \tTraining Loss: 0.116803 \t valid Loss: 0.119729\n",
      "Epoch: 39 \tTraining Loss: 0.114537 \t valid Loss: 0.107121\n",
      "Epoch: 40 \tTraining Loss: 0.110612 \t valid Loss: 0.104702\n",
      "Epoch: 41 \tTraining Loss: 0.108142 \t valid Loss: 0.105985\n",
      "Epoch: 42 \tTraining Loss: 0.107152 \t valid Loss: 0.097986\n",
      "Epoch: 43 \tTraining Loss: 0.101340 \t valid Loss: 0.104651\n",
      "Epoch: 44 \tTraining Loss: 0.098755 \t valid Loss: 0.093605\n",
      "Epoch: 45 \tTraining Loss: 0.097974 \t valid Loss: 0.095202\n",
      "Epoch: 46 \tTraining Loss: 0.095833 \t valid Loss: 0.090579\n",
      "Epoch: 47 \tTraining Loss: 0.092096 \t valid Loss: 0.092015\n",
      "Epoch: 48 \tTraining Loss: 0.091083 \t valid Loss: 0.093373\n",
      "Epoch: 49 \tTraining Loss: 0.087506 \t valid Loss: 0.090192\n",
      "Epoch: 50 \tTraining Loss: 0.087454 \t valid Loss: 0.083009\n",
      "Epoch: 51 \tTraining Loss: 0.087482 \t valid Loss: 0.085808\n",
      "Epoch: 52 \tTraining Loss: 0.082824 \t valid Loss: 0.086343\n",
      "Epoch: 53 \tTraining Loss: 0.083300 \t valid Loss: 0.081269\n",
      "Epoch: 54 \tTraining Loss: 0.079906 \t valid Loss: 0.079302\n",
      "Epoch: 55 \tTraining Loss: 0.080861 \t valid Loss: 0.074926\n",
      "Epoch: 56 \tTraining Loss: 0.078233 \t valid Loss: 0.076228\n",
      "Epoch: 57 \tTraining Loss: 0.075981 \t valid Loss: 0.070652\n",
      "Epoch: 58 \tTraining Loss: 0.076437 \t valid Loss: 0.072051\n",
      "Epoch: 59 \tTraining Loss: 0.076466 \t valid Loss: 0.071707\n",
      "Epoch: 60 \tTraining Loss: 0.075471 \t valid Loss: 0.069482\n",
      "Epoch: 61 \tTraining Loss: 0.074232 \t valid Loss: 0.073597\n",
      "Epoch: 62 \tTraining Loss: 0.072513 \t valid Loss: 0.070658\n",
      "Epoch: 63 \tTraining Loss: 0.070157 \t valid Loss: 0.067516\n",
      "Epoch: 64 \tTraining Loss: 0.069066 \t valid Loss: 0.071085\n",
      "Epoch: 65 \tTraining Loss: 0.069360 \t valid Loss: 0.068468\n",
      "Epoch: 66 \tTraining Loss: 0.068703 \t valid Loss: 0.071042\n",
      "Epoch: 67 \tTraining Loss: 0.067217 \t valid Loss: 0.068367\n",
      "Epoch: 68 \tTraining Loss: 0.066484 \t valid Loss: 0.067676\n",
      "Epoch: 69 \tTraining Loss: 0.068121 \t valid Loss: 0.066643\n",
      "Epoch: 70 \tTraining Loss: 0.063785 \t valid Loss: 0.065562\n",
      "Epoch: 71 \tTraining Loss: 0.064902 \t valid Loss: 0.064735\n",
      "Epoch: 72 \tTraining Loss: 0.065564 \t valid Loss: 0.062789\n",
      "Epoch: 73 \tTraining Loss: 0.064563 \t valid Loss: 0.066623\n",
      "Epoch: 74 \tTraining Loss: 0.064154 \t valid Loss: 0.060814\n",
      "Epoch: 75 \tTraining Loss: 0.062831 \t valid Loss: 0.062199\n",
      "Epoch: 76 \tTraining Loss: 0.063024 \t valid Loss: 0.065807\n",
      "Epoch: 77 \tTraining Loss: 0.060637 \t valid Loss: 0.061993\n",
      "Epoch: 78 \tTraining Loss: 0.062310 \t valid Loss: 0.057352\n",
      "Epoch: 79 \tTraining Loss: 0.061903 \t valid Loss: 0.060263\n",
      "Epoch: 80 \tTraining Loss: 0.062864 \t valid Loss: 0.058798\n",
      "Epoch: 81 \tTraining Loss: 0.060293 \t valid Loss: 0.059399\n",
      "Epoch: 82 \tTraining Loss: 0.062716 \t valid Loss: 0.055823\n",
      "Epoch: 83 \tTraining Loss: 0.059167 \t valid Loss: 0.060755\n",
      "Epoch: 84 \tTraining Loss: 0.061223 \t valid Loss: 0.056073\n",
      "Epoch: 85 \tTraining Loss: 0.059261 \t valid Loss: 0.056406\n",
      "Epoch: 86 \tTraining Loss: 0.059602 \t valid Loss: 0.061173\n",
      "Epoch: 87 \tTraining Loss: 0.059357 \t valid Loss: 0.057104\n",
      "Epoch: 88 \tTraining Loss: 0.060321 \t valid Loss: 0.053000\n",
      "Epoch: 89 \tTraining Loss: 0.059877 \t valid Loss: 0.061364\n",
      "Epoch: 90 \tTraining Loss: 0.057079 \t valid Loss: 0.059855\n",
      "Epoch: 91 \tTraining Loss: 0.055535 \t valid Loss: 0.054615\n",
      "Epoch: 92 \tTraining Loss: 0.059110 \t valid Loss: 0.060783\n",
      "Epoch: 93 \tTraining Loss: 0.056928 \t valid Loss: 0.057736\n",
      "Epoch: 94 \tTraining Loss: 0.057532 \t valid Loss: 0.059533\n",
      "Epoch: 95 \tTraining Loss: 0.057238 \t valid Loss: 0.056895\n",
      "Epoch: 96 \tTraining Loss: 0.056511 \t valid Loss: 0.056536\n",
      "alex training end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg training start\n",
      "Epoch: 1 \tTraining Loss: 1.145401 \t valid Loss: 0.970190\n",
      "Epoch: 2 \tTraining Loss: 0.749656 \t valid Loss: 0.734735\n",
      "Epoch: 3 \tTraining Loss: 0.602140 \t valid Loss: 0.572750\n",
      "Epoch: 4 \tTraining Loss: 0.479379 \t valid Loss: 0.539440\n",
      "Epoch: 5 \tTraining Loss: 0.385383 \t valid Loss: 0.300648\n",
      "Epoch: 6 \tTraining Loss: 0.290644 \t valid Loss: 0.313017\n",
      "Epoch: 7 \tTraining Loss: 0.209559 \t valid Loss: 0.209546\n",
      "Epoch: 8 \tTraining Loss: 0.140207 \t valid Loss: 0.126249\n",
      "Epoch: 9 \tTraining Loss: 0.097055 \t valid Loss: 0.076553\n",
      "Epoch: 10 \tTraining Loss: 0.062212 \t valid Loss: 0.055169\n",
      "Epoch: 11 \tTraining Loss: 0.042785 \t valid Loss: 0.042623\n",
      "Epoch: 12 \tTraining Loss: 0.032881 \t valid Loss: 0.023752\n",
      "Epoch: 13 \tTraining Loss: 0.025718 \t valid Loss: 0.022623\n",
      "Epoch: 14 \tTraining Loss: 0.020422 \t valid Loss: 0.016919\n",
      "Epoch: 15 \tTraining Loss: 0.017664 \t valid Loss: 0.021452\n",
      "Epoch: 16 \tTraining Loss: 0.013805 \t valid Loss: 0.015601\n",
      "Epoch: 17 \tTraining Loss: 0.013066 \t valid Loss: 0.013860\n",
      "Epoch: 18 \tTraining Loss: 0.011326 \t valid Loss: 0.012921\n",
      "Epoch: 19 \tTraining Loss: 0.010308 \t valid Loss: 0.008532\n",
      "Epoch: 20 \tTraining Loss: 0.008967 \t valid Loss: 0.009512\n",
      "Epoch: 21 \tTraining Loss: 0.008719 \t valid Loss: 0.008063\n",
      "Epoch: 22 \tTraining Loss: 0.007679 \t valid Loss: 0.007115\n",
      "Epoch: 23 \tTraining Loss: 0.007200 \t valid Loss: 0.005601\n",
      "Epoch: 24 \tTraining Loss: 0.006752 \t valid Loss: 0.005745\n",
      "Epoch: 25 \tTraining Loss: 0.006457 \t valid Loss: 0.005648\n",
      "Epoch: 26 \tTraining Loss: 0.005533 \t valid Loss: 0.005451\n",
      "Epoch: 27 \tTraining Loss: 0.005486 \t valid Loss: 0.005683\n",
      "Epoch: 28 \tTraining Loss: 0.005358 \t valid Loss: 0.005332\n",
      "Epoch: 29 \tTraining Loss: 0.005131 \t valid Loss: 0.004260\n",
      "Epoch: 30 \tTraining Loss: 0.004732 \t valid Loss: 0.004278\n",
      "Epoch: 31 \tTraining Loss: 0.004732 \t valid Loss: 0.004551\n",
      "Epoch: 32 \tTraining Loss: 0.004355 \t valid Loss: 0.005435\n",
      "Epoch: 33 \tTraining Loss: 0.003817 \t valid Loss: 0.004127\n",
      "Epoch: 34 \tTraining Loss: 0.004029 \t valid Loss: 0.003818\n",
      "Epoch: 35 \tTraining Loss: 0.003846 \t valid Loss: 0.003667\n",
      "Epoch: 36 \tTraining Loss: 0.003814 \t valid Loss: 0.003463\n",
      "Epoch: 37 \tTraining Loss: 0.003508 \t valid Loss: 0.003160\n",
      "Epoch: 38 \tTraining Loss: 0.003599 \t valid Loss: 0.003040\n",
      "Epoch: 39 \tTraining Loss: 0.003532 \t valid Loss: 0.003162\n",
      "Epoch: 40 \tTraining Loss: 0.003578 \t valid Loss: 0.003286\n",
      "Epoch: 41 \tTraining Loss: 0.003204 \t valid Loss: 0.003185\n",
      "Epoch: 42 \tTraining Loss: 0.003197 \t valid Loss: 0.003109\n",
      "Epoch: 43 \tTraining Loss: 0.003079 \t valid Loss: 0.003320\n",
      "Epoch: 44 \tTraining Loss: 0.003028 \t valid Loss: 0.002739\n",
      "Epoch: 45 \tTraining Loss: 0.002913 \t valid Loss: 0.003380\n",
      "Epoch: 46 \tTraining Loss: 0.003042 \t valid Loss: 0.002690\n",
      "Epoch: 47 \tTraining Loss: 0.002907 \t valid Loss: 0.002558\n",
      "Epoch: 48 \tTraining Loss: 0.002932 \t valid Loss: 0.002631\n",
      "Epoch: 49 \tTraining Loss: 0.002726 \t valid Loss: 0.002668\n",
      "Epoch: 50 \tTraining Loss: 0.002684 \t valid Loss: 0.002434\n",
      "Epoch: 51 \tTraining Loss: 0.002512 \t valid Loss: 0.002688\n",
      "Epoch: 52 \tTraining Loss: 0.002457 \t valid Loss: 0.002338\n",
      "Epoch: 53 \tTraining Loss: 0.002705 \t valid Loss: 0.002192\n",
      "Epoch: 54 \tTraining Loss: 0.002385 \t valid Loss: 0.002663\n",
      "Epoch: 55 \tTraining Loss: 0.002384 \t valid Loss: 0.002488\n",
      "Epoch: 56 \tTraining Loss: 0.002403 \t valid Loss: 0.002356\n",
      "Epoch: 57 \tTraining Loss: 0.002362 \t valid Loss: 0.002282\n",
      "Epoch: 58 \tTraining Loss: 0.002364 \t valid Loss: 0.002614\n",
      "Epoch: 59 \tTraining Loss: 0.002248 \t valid Loss: 0.002396\n",
      "Epoch: 60 \tTraining Loss: 0.002432 \t valid Loss: 0.002440\n",
      "Epoch: 61 \tTraining Loss: 0.002264 \t valid Loss: 0.002319\n",
      "vgg training end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet training start\n",
      "Epoch: 1 \tTraining Loss: 3.002755 \t valid Loss: 2.676890\n",
      "Epoch: 2 \tTraining Loss: 1.961365 \t valid Loss: 1.985894\n",
      "Epoch: 3 \tTraining Loss: 1.764967 \t valid Loss: 1.509495\n",
      "Epoch: 4 \tTraining Loss: 1.617515 \t valid Loss: 1.402955\n",
      "Epoch: 5 \tTraining Loss: 1.561471 \t valid Loss: 1.784751\n",
      "Epoch: 6 \tTraining Loss: 1.455560 \t valid Loss: 1.549729\n",
      "Epoch: 7 \tTraining Loss: 1.389772 \t valid Loss: 2.413439\n",
      "Epoch: 8 \tTraining Loss: 1.361637 \t valid Loss: 1.372078\n",
      "Epoch: 9 \tTraining Loss: 1.288719 \t valid Loss: 1.601582\n",
      "Epoch: 10 \tTraining Loss: 1.252534 \t valid Loss: 1.120561\n",
      "Epoch: 11 \tTraining Loss: 1.211611 \t valid Loss: 1.697971\n",
      "Epoch: 12 \tTraining Loss: 1.191753 \t valid Loss: 1.268425\n",
      "Epoch: 13 \tTraining Loss: 1.138674 \t valid Loss: 1.093187\n",
      "Epoch: 14 \tTraining Loss: 1.140171 \t valid Loss: 1.236370\n",
      "Epoch: 15 \tTraining Loss: 1.094961 \t valid Loss: 1.089924\n",
      "Epoch: 16 \tTraining Loss: 1.073446 \t valid Loss: 1.219008\n",
      "Epoch: 17 \tTraining Loss: 1.056819 \t valid Loss: 1.106549\n",
      "Epoch: 18 \tTraining Loss: 1.044197 \t valid Loss: 1.027408\n",
      "Epoch: 19 \tTraining Loss: 1.035209 \t valid Loss: 1.225179\n",
      "Epoch: 20 \tTraining Loss: 1.022905 \t valid Loss: 1.122805\n",
      "Epoch: 21 \tTraining Loss: 1.012166 \t valid Loss: 1.135076\n",
      "Epoch: 22 \tTraining Loss: 1.006901 \t valid Loss: 1.073515\n",
      "Epoch: 23 \tTraining Loss: 0.985978 \t valid Loss: 1.171718\n",
      "Epoch: 24 \tTraining Loss: 0.985154 \t valid Loss: 1.191049\n",
      "Epoch: 25 \tTraining Loss: 0.983715 \t valid Loss: 1.037500\n",
      "Epoch: 26 \tTraining Loss: 0.978352 \t valid Loss: 1.048173\n",
      "resnet training end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minki\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet161_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet161_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenet training start\n",
      "Epoch: 1 \tTraining Loss: 2.012583 \t valid Loss: 1.663062\n",
      "Epoch: 2 \tTraining Loss: 1.466452 \t valid Loss: 1.567900\n",
      "Epoch: 3 \tTraining Loss: 1.368739 \t valid Loss: 1.329501\n",
      "Epoch: 4 \tTraining Loss: 1.286107 \t valid Loss: 1.609982\n",
      "Epoch: 5 \tTraining Loss: 1.275280 \t valid Loss: 1.217026\n",
      "Epoch: 6 \tTraining Loss: 1.225415 \t valid Loss: 1.428956\n",
      "Epoch: 7 \tTraining Loss: 1.210452 \t valid Loss: 1.481516\n",
      "Epoch: 8 \tTraining Loss: 1.193926 \t valid Loss: 1.349013\n",
      "Epoch: 9 \tTraining Loss: 1.161560 \t valid Loss: 1.236330\n",
      "Epoch: 10 \tTraining Loss: 1.134310 \t valid Loss: 1.456598\n",
      "Epoch: 11 \tTraining Loss: 1.128933 \t valid Loss: 1.160844\n",
      "Epoch: 12 \tTraining Loss: 1.129263 \t valid Loss: 1.125249\n",
      "Epoch: 13 \tTraining Loss: 1.102995 \t valid Loss: 1.090898\n",
      "Epoch: 14 \tTraining Loss: 1.105141 \t valid Loss: 1.117067\n",
      "Epoch: 15 \tTraining Loss: 1.085370 \t valid Loss: 1.117603\n",
      "Epoch: 16 \tTraining Loss: 1.083056 \t valid Loss: 1.151514\n",
      "Epoch: 17 \tTraining Loss: 1.065254 \t valid Loss: 1.185742\n",
      "Epoch: 18 \tTraining Loss: 1.066329 \t valid Loss: 1.215007\n",
      "Epoch: 19 \tTraining Loss: 1.059387 \t valid Loss: 1.194448\n",
      "Epoch: 20 \tTraining Loss: 1.047175 \t valid Loss: 1.096342\n",
      "Epoch: 21 \tTraining Loss: 1.043230 \t valid Loss: 1.024635\n",
      "Epoch: 22 \tTraining Loss: 1.038290 \t valid Loss: 1.222891\n",
      "Epoch: 23 \tTraining Loss: 1.042712 \t valid Loss: 1.103353\n",
      "Epoch: 24 \tTraining Loss: 1.031944 \t valid Loss: 1.040906\n",
      "Epoch: 25 \tTraining Loss: 1.024882 \t valid Loss: 1.028407\n",
      "Epoch: 26 \tTraining Loss: 1.021238 \t valid Loss: 1.099897\n",
      "Epoch: 27 \tTraining Loss: 1.021013 \t valid Loss: 1.325275\n",
      "Epoch: 28 \tTraining Loss: 1.019022 \t valid Loss: 1.070281\n",
      "Epoch: 29 \tTraining Loss: 1.015448 \t valid Loss: 1.091892\n",
      "densenet training end\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "acc_dic = dict()\n",
    "for model_name in ['alex','vgg','resnet','densenet']:\n",
    "    training_dic = {\n",
    "        'train_loss' : [] , 'valid_loss' : []\n",
    "    }\n",
    "\n",
    "    model = load_finetuned_model(model_name,update_conv=False)\n",
    "    model.to(device)\n",
    "    print(f'{model_name} training start')\n",
    "    training_dic['train_loss'] , training_dic['valid_loss'] = training_model(model_name,model,trainloader,validloader,device)\n",
    "    print(f'{model_name} training end')\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alex=========================================================\n",
      "Test Loss: 0.920206\n",
      "\n",
      "Test Accuracy of     0: 78% (786/1000)\n",
      "Test Accuracy of     1: 82% (827/1000)\n",
      "Test Accuracy of     2: 68% (686/1000)\n",
      "Test Accuracy of     3: 55% (559/1000)\n",
      "Test Accuracy of     4: 73% (735/1000)\n",
      "Test Accuracy of     5: 68% (688/1000)\n",
      "Test Accuracy of     6: 82% (822/1000)\n",
      "Test Accuracy of     7: 80% (807/1000)\n",
      "Test Accuracy of     8: 85% (854/1000)\n",
      "Test Accuracy of     9: 83% (830/1000)\n",
      "\n",
      "Test Accuracy (Overall): 75% (7594/10000)\n",
      "==========================================================================\n",
      "\n",
      "vgg=========================================================\n",
      "Test Loss: 0.972574\n",
      "\n",
      "Test Accuracy of     0: 85% (851/1000)\n",
      "Test Accuracy of     1: 91% (915/1000)\n",
      "Test Accuracy of     2: 71% (712/1000)\n",
      "Test Accuracy of     3: 66% (661/1000)\n",
      "Test Accuracy of     4: 76% (764/1000)\n",
      "Test Accuracy of     5: 68% (682/1000)\n",
      "Test Accuracy of     6: 83% (837/1000)\n",
      "Test Accuracy of     7: 82% (820/1000)\n",
      "Test Accuracy of     8: 89% (894/1000)\n",
      "Test Accuracy of     9: 89% (895/1000)\n",
      "\n",
      "Test Accuracy (Overall): 80% (8031/10000)\n",
      "==========================================================================\n",
      "\n",
      "resnet=========================================================\n",
      "Test Loss: 1.201629\n",
      "\n",
      "Test Accuracy of     0: 69% (691/1000)\n",
      "Test Accuracy of     1: 60% (609/1000)\n",
      "Test Accuracy of     2: 38% (387/1000)\n",
      "Test Accuracy of     3: 69% (695/1000)\n",
      "Test Accuracy of     4: 54% (546/1000)\n",
      "Test Accuracy of     5: 39% (398/1000)\n",
      "Test Accuracy of     6: 67% (670/1000)\n",
      "Test Accuracy of     7: 54% (545/1000)\n",
      "Test Accuracy of     8: 76% (769/1000)\n",
      "Test Accuracy of     9: 65% (654/1000)\n",
      "\n",
      "Test Accuracy (Overall): 59% (5964/10000)\n",
      "==========================================================================\n",
      "\n",
      "densenet=========================================================\n",
      "Test Loss: 1.182809\n",
      "\n",
      "Test Accuracy of     0: 52% (521/1000)\n",
      "Test Accuracy of     1: 75% (751/1000)\n",
      "Test Accuracy of     2: 39% (397/1000)\n",
      "Test Accuracy of     3: 31% (318/1000)\n",
      "Test Accuracy of     4: 48% (480/1000)\n",
      "Test Accuracy of     5: 64% (643/1000)\n",
      "Test Accuracy of     6: 77% (770/1000)\n",
      "Test Accuracy of     7: 61% (615/1000)\n",
      "Test Accuracy of     8: 77% (779/1000)\n",
      "Test Accuracy of     9: 70% (701/1000)\n",
      "\n",
      "Test Accuracy (Overall): 59% (5975/10000)\n",
      "==========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "for model_name in ['alex','vgg','resnet','densenet']:\n",
    "    model = load_finetuned_model(model_name)\n",
    "    model.to(device)\n",
    "    test_model(model_name,model,testloader,device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||test_acc|error_rate|train_loss|valid_loss|epoch|\n",
    "|------|---|---|---|---|---|\n",
    "|AlexNet|%|%|0.0603|0.0530|88|\n",
    "|AlexNet with conv train|%|%||||\n",
    "|VGG19|%|%|0.0022|0.0023|53|\n",
    "|VGG19 with conv train|%|%||||\n",
    "|ResNet50|%|%|1.0441|1.0274|18|\n",
    "|ResNet50 with conv train|%|%||||\n",
    "|DenseNet161|%|%||||\n",
    "|DenseNet161 with conv train|%|%||||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02180653753474073"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.97**50*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
